{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview \n",
    "\n",
    "a classification algorithm used to predict binary outcomes (e.g. 0 or 1, Yes or No). It models the probability that a given input belongs to a particular class\n",
    "\n",
    "### Loss function \n",
    "$$\n",
    "P(y = 1 \\mid X) = \\frac{1}{1 + e^{-(w^T X + b)}}\n",
    "$$\n",
    "\n",
    "## Goal\n",
    "the goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation\n",
    "We want to find parameters w and b such that the predicted probabilities y^ are as close as possible to the actual labels y âˆˆ {0,1}\n",
    "\n",
    "\n",
    "### Training\n",
    "Goal: the goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation\n",
    "sigmoid classifier help with that \n",
    "\n",
    "* Optimized using gradient descent or variants (SGD, Adam, etc.)\n",
    "* Often regularized: L2 (Ridge) or L1 (Lasso)\n",
    "\n",
    "\n",
    "### Prediction\n",
    "Output is a probability between 0 and 1\n",
    "\n",
    "\n",
    "### Pros and cons\n",
    "+ Simple and fast\n",
    "+ Interpretable model\n",
    "+ Good baseline for binary classification\n",
    "- Assumes linear relationship in log-odds\n",
    "- Poor at handling complex nonlinear patterns (without feature engineering)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
